{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multimodal RAG\n",
    "\n",
    "- Author: [Mark](https://github.com/obov)\n",
    "- Design:\n",
    "- Peer Review :\n",
    "- This is a part of [LangChain Open Tutorial](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial)\n",
    "\n",
    "## Overview\n",
    "\n",
    "This tutorial demonstrates how to build an **Onboarding Helper** using **LangChain**, designed to centralize and leverage **Notion-based documentation** for new employees. By integrating structured data from Notion pages, databases, and wikis into a **Retrieval-Augmented Generation (RAG)** system, the solution enables seamless access to company protocols, role-specific guides, and FAQs. New hires can query this unified knowledge base in natural language to rapidly adapt to their roles.\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "- [Overview](#overview)\n",
    "- [Environment Setup](#environment-setup)\n",
    "- [Notion Database Setup](#notion-database-setup)\n",
    "- [Langchain Only RAG](#langchain-only-rag)\n",
    "- [Apply Langgraph Basic](#apply-langgraph-step1)\n",
    "- [Apply Langgraph Advanced](#apply-langgraph-step2)\n",
    "\n",
    "### References\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "Set up the environment. You may refer to [Environment Setup](https://wikidocs.net/257836) for more details.\n",
    "\n",
    "**[Note]**\n",
    "\n",
    "- `langchain-opentutorial` is a package that provides a set of easy-to-use environment setup, useful functions and utilities for tutorials.\n",
    "- You can checkout the [`langchain-opentutorial`](https://github.com/LangChain-OpenTutorial/langchain-opentutorial-pypi) for more details.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install langchain-opentutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "from langchain_opentutorial import package\n",
    "\n",
    "package.install(\n",
    "    [\n",
    "        \"langchain-community\",\n",
    "        \"langchain-openai\",\n",
    "        \"langchain-chroma\",\n",
    "        \"langchain-core\",\n",
    "    ],\n",
    "    verbose=False,\n",
    "    upgrade=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variables have been set successfully.\n"
     ]
    }
   ],
   "source": [
    "# Set environment variables\n",
    "from langchain_opentutorial import set_env\n",
    "\n",
    "set_env(\n",
    "    {\n",
    "        # \"LANGCHAIN_API_KEY\": \"\",\n",
    "        # \"LANGCHAIN_TRACING_V2\": \"true\",\n",
    "        # \"LANGCHAIN_ENDPOINT\": \"https://api.smith.langchain.com\",\n",
    "        # \"LANGCHAIN_PROJECT\": \"07-Agent\",\n",
    "        # \"UPSTAGE_API_KEY\": \"\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notion Database Setup\n",
    "\n",
    "We use **Notion** as our central hub for team wikis, documentation, and task management. Think of it as a flexible digital workspace that combines note-taking, databases, and collaboration tools.\n",
    "\n",
    "Key Concepts of Notion:\n",
    "\n",
    "- **Pages**: Individual documents (like this guide) for text, images, or embedded content.\n",
    "- **Databases**: Structured tables that organize information (e.g., tasks, project trackers, SOPs) with filter/sort capabilities.\n",
    "\n",
    "### Example Database\n",
    "\n",
    "You can view with the **exact Notion database** used in this tutorial here: [Tutorial Example Database](https://shrouded-lantana-c42.notion.site/1870d31b38698044b3f2fdd3c2c15e4c?v=1870d31b38698086a4dd000cd1ddd37a&pvs=4)\n",
    "\n",
    "There is a list of documents for Retrieval Augmented Generation (RAG). Every document is augmented for this tutorial. Names and contents are all virtual data.\n",
    "\n",
    "### Setup Notion Integration\n",
    "\n",
    "to use Notion as a knowledge base, you need to create a Notion integration.\n",
    "\n",
    "#### 1. Get API Key\n",
    "\n",
    "1. **Go to Notion Developers**:  \n",
    "   Log in to [Notion Developers](https://developers.notion.com) → Click \"View my integrations\".\n",
    "2. **Create a New Integration**:\n",
    "   - Click \"New integration\".\n",
    "   - Name it (e.g., MyApp Integration).\n",
    "   - Select your workspace.\n",
    "   - Set permissions:\n",
    "     - Read content\n",
    "     - Update content (if needed)\n",
    "3. **Copy the API Key**:  \n",
    "   After creation, copy the **Internal Integration Token**\n",
    "4. **More Information**:\n",
    "   - [Notion API Documentation](https://developers.notion.com/reference/intro)\n",
    "   - [Notion API Key](https://developers.notion.com/docs/create-a-notion-integration)\n",
    "\n",
    "#### 2. Find Database ID\n",
    "\n",
    "1. **Open Notion Database**:\n",
    "   Go to the database you or your team want to use → Click \"Share\" → \"Copy link\".\n",
    "\n",
    "2. **Extract the ID**:  \n",
    "   The URL looks like:  \n",
    "   https://www.notion.so/your-workspace/{DATABASE_ID}?v=...  \n",
    "   Copy the **32-character string** between / and ? (e.g., 1870d31b38698044b3f2fdd3c2c15e4c).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import NotionDBLoader\n",
    "\n",
    "NOTION_TOKEN = \"ntn\" + \"_L3541776489aPP4RRULRr1dAfxDeeeBoJUufhX8ON0y4tM\"\n",
    "DATABASE_ID = \"1870d31b38698044b3f2fdd3c2c15e4c\"\n",
    "\n",
    "loader = NotionDBLoader(\n",
    "    integration_token=NOTION_TOKEN,\n",
    "    database_id=DATABASE_ID,\n",
    ")\n",
    "\n",
    "data = loader.load()\n",
    "\n",
    "# If you can see list of documents, it means you successfully loaded the data from Notion.\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On Boarding \n",
      "['Task']\n",
      "New Hire Onboarding Seminar\n",
      ": Held on the first Monday of each month at 2 PM in the 10F auditorium.  \n",
      "Team Wikis/Notion\n",
      ": Check department-specific wikis for detailed work manuals and FAQs.  \n",
      "Company Notices\n",
      ": [notice.xyzshop.com](https://notice.xyzshop.com/) updates daily with announcements.\n"
     ]
    }
   ],
   "source": [
    "print(data[0].metadata[\"title\"])\n",
    "print(data[0].metadata[\"tags\"])\n",
    "print(data[0].page_content[:800])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Langchain Only RAG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "data_processed = [\n",
    "    *[\n",
    "        Document(\n",
    "            page_content=item.page_content,\n",
    "            metadata={\n",
    "                # Attributes\n",
    "                \"title\": item.metadata[\"title\"],\n",
    "                \"use_title_as_page_content\": False,\n",
    "            },\n",
    "        )\n",
    "        for item in data\n",
    "    ],\n",
    "    *[\n",
    "        Document(\n",
    "            # Use title as page content for similarity search\n",
    "            # If you want some documents to be retrieved more frequently, you can use this method\n",
    "            page_content=item.metadata[\"title\"],\n",
    "            metadata={\n",
    "                # Attributes\n",
    "                \"page_content\": item.page_content,\n",
    "                \"title\": item.metadata[\"title\"],\n",
    "                \"use_title_as_page_content\": True,\n",
    "            },\n",
    "        )\n",
    "        for item in data\n",
    "    ],\n",
    "]\n",
    "\n",
    "\n",
    "vector_store = Chroma.from_documents(\n",
    "    documents=data_processed,\n",
    "    embedding=OpenAIEmbeddings(),\n",
    ")\n",
    "\n",
    "retriever_from_notion = vector_store.as_retriever(\n",
    "    search_kwargs={\n",
    "        \"k\": 5,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import chain\n",
    "from typing import List\n",
    "\n",
    "\n",
    "@chain\n",
    "def context_parser(docs: List[Document]) -> str:\n",
    "    return \"\\n\\n\".join(\n",
    "        [\n",
    "            f\"# {doc.metadata['title']}\\n\"\n",
    "            f\"{doc.metadata['page_content'] if doc.metadata['use_title_as_page_content'] else doc.page_content}\"\n",
    "            for doc in docs\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant for onboarding new employees. \\n\"\n",
    "            \"Please answer the question based on the following documents. \\n\"\n",
    "            \"Documents: \\n\"\n",
    "            \"{context}\",\n",
    "        ),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To use a conference room at XYZ Shopping Mall, follow these steps:\n",
      "\n",
      "1. **Login:**\n",
      "   - Access the internal portal at [meet.xyzshop.com](https://meet.xyzshop.com/).\n",
      "   - Log in using your `@xyzshop.com` account through Single Sign-On (SSO).\n",
      "   - Approve the “Meeting Room Booking” permissions when prompted.\n",
      "\n",
      "2. **View Meeting Rooms & Schedule:**\n",
      "   - Navigate through the available rooms per floor (e.g., “10F-Alpha Room,” “10F-Beta Room,” “11F-Gamma Room,” etc.).\n",
      "   - Check the availability of the rooms in a calendar view.\n",
      "\n",
      "3. **Booking Procedure:**\n",
      "   - Click on an open time slot to proceed with booking.\n",
      "   - Fill out the request form with the following details:\n",
      "     - Meeting Title\n",
      "     - Number of Attendees\n",
      "     - Required Equipment (e.g., projector, video conference tools).\n",
      "   - Once booked, a Google Calendar invite will be automatically sent to all participants.\n",
      "\n",
      "4. **Cancellation/Changes:**\n",
      "   - If you need to cancel or change the reservation, click “Cancel” on the reservation detail page.\n",
      "   - The event will be removed from the calendar, and cancellation notices will be sent to all invitees.\n",
      "   - The same process applies for making changes to the reservation.\n",
      "\n",
      "By following these steps, you can successfully reserve and use a conference room at XYZ Shopping Mall.\n"
     ]
    }
   ],
   "source": [
    "## Use LangChain Only\n",
    "\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "langchain_only_rag_chatbot = (\n",
    "    {\n",
    "        \"question\": RunnablePassthrough(),\n",
    "        \"context\": retriever_from_notion | context_parser,\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    ")\n",
    "\n",
    "result = langchain_only_rag_chatbot.invoke(\"how to use conference room?\")\n",
    "\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Langgraph Basic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply LangGraph to retriever_from_notion\n",
    "\n",
    "from langgraph.graph import StateGraph\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from typing import TypedDict, List\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from functools import reduce\n",
    "\n",
    "prompt_relevance_check = ChatPromptTemplate(\n",
    "    [\n",
    "        \"Please determine whether the following question is relevant to the retrieved document.\\n\"\n",
    "        \"If it is relevant, output 'yes'; otherwise, output 'no' only.\\n\"\n",
    "        \"Question: {question}\\n\"\n",
    "        \"Retrieved Document:\\n\"\n",
    "        \"{context}\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "class RetrievalState(TypedDict):\n",
    "    question: str\n",
    "    retrieved_docs: List[Document]\n",
    "    relevant_docs: List[Document]\n",
    "\n",
    "\n",
    "# retriever_from_notion\n",
    "def retrieve_node(state: RetrievalState) -> RetrievalState:\n",
    "    question = state[\"question\"]\n",
    "    return {\n",
    "        \"question\": question,\n",
    "        \"retrieved_docs\": retriever_from_notion.invoke(question),\n",
    "        \"relevant_docs\": [],\n",
    "    }\n",
    "\n",
    "\n",
    "def filter_relevant_docs_node(state: RetrievalState) -> RetrievalState:\n",
    "    question = state[\"question\"]\n",
    "    docs = state[\"retrieved_docs\"]\n",
    "    if not docs:\n",
    "        return {\n",
    "            \"question\": question,\n",
    "            \"retrieved_docs\": docs,\n",
    "            \"relevant_docs\": [],\n",
    "        }\n",
    "    idxed_docs = reduce(\n",
    "        lambda acc, item: {**acc, item[0]: item[1]},\n",
    "        enumerate(docs),\n",
    "        {},\n",
    "    )\n",
    "\n",
    "    is_each_docs_relevant_chain = RunnableParallel(\n",
    "        # Dynamically create a chain as documents retrieved\n",
    "        {\n",
    "            str(idx): {\n",
    "                \"question\": RunnablePassthrough(),\n",
    "                \"context\": RunnableLambda(\n",
    "                    lambda _, doc=doc: context_parser.invoke([doc])\n",
    "                ),\n",
    "            }\n",
    "            | prompt_relevance_check\n",
    "            | llm\n",
    "            | StrOutputParser()\n",
    "            for idx, doc in idxed_docs.items()\n",
    "        }\n",
    "    ) | RunnableLambda(lambda result: list(result.values()))\n",
    "\n",
    "    relevance_response = is_each_docs_relevant_chain.invoke(question)\n",
    "    print(relevance_response)  # ['yes', 'yes', 'no']\n",
    "\n",
    "    return {\n",
    "        \"question\": question,\n",
    "        \"retrieved_docs\": docs,\n",
    "        \"relevant_docs\": [\n",
    "            doc for doc, flag in zip(docs, relevance_response) if flag == \"yes\"\n",
    "        ],\n",
    "    }\n",
    "\n",
    "\n",
    "graph = StateGraph(state_schema=RetrievalState)\n",
    "\n",
    "graph.add_node(\"retrieve\", retrieve_node)\n",
    "graph.add_node(\"filter_relevant_docs\", filter_relevant_docs_node)\n",
    "\n",
    "graph.set_entry_point(\"retrieve\")\n",
    "graph.add_edge(\"retrieve\", \"filter_relevant_docs\")\n",
    "\n",
    "langgraph_retriever = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['yes', 'yes', 'yes', 'yes', 'yes']\n",
      "how to use conference room?\n",
      "5\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "langgraph_retriever_result = langgraph_retriever.invoke(\n",
    "    {\"question\": \"how to use conference room?\"}\n",
    ")\n",
    "print(langgraph_retriever_result[\"question\"])\n",
    "print(len(langgraph_retriever_result[\"retrieved_docs\"]))\n",
    "print(len(langgraph_retriever_result[\"relevant_docs\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "langgraph_applied_rag = (\n",
    "    {\n",
    "        \"question\": RunnablePassthrough(),\n",
    "        # LangGraph applied to retriever_from_notion\n",
    "        # before: \"context\": retriever_from_notion | context_parser,\n",
    "        \"context\": {\n",
    "            \"question\": RunnablePassthrough(),\n",
    "        }\n",
    "        | langgraph_retriever\n",
    "        | RunnableLambda(lambda result: result[\"relevant_docs\"])\n",
    "        | context_parser,\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['yes', 'yes', 'yes', 'yes', 'yes']\n",
      "To use a conference room at XYZ Shopping Mall, follow these steps:\n",
      "\n",
      "1. **Login**: Access the internal portal at [meet.xyzshop.com](https://meet.xyzshop.com/) using Single Sign-On (SSO) with your `@xyzshop.com` account. Approve any prompts for “Meeting Room Booking” permissions.\n",
      "\n",
      "2. **View Meeting Rooms & Schedule**: Browse the available conference rooms, which are listed per floor (e.g., “10F-Alpha Room,” “10F-Beta Room,” “11F-Gamma Room,” etc.). Check the availability of rooms in the calendar view and click on an open time slot to start the booking process.\n",
      "\n",
      "3. **Booking Procedure**:\n",
      "   - Fill out the booking request form with the following details:\n",
      "     - Meeting Title\n",
      "     - Number of Attendees\n",
      "     - Required Equipment (e.g., projector, video conference tools)\n",
      "   - After successfully booking the room, a Google Calendar invite will automatically be sent to all participants.\n",
      "\n",
      "4. **Handling Conflicts**: If there is a scheduling conflict, the system will suggest alternative rooms or times for your meeting.\n",
      "\n",
      "5. **Cancellation/Changes**:\n",
      "   - If you need to cancel your reservation, click “Cancel” on the reservation detail page. This action will remove the event from the calendar and send cancellation notices to all invitees.\n",
      "   - For any changes to the booking, follow the same procedure, ensuring all participants are kept updated.\n",
      "\n",
      "By following these steps, you can effectively book and use a conference room for your meetings.\n"
     ]
    }
   ],
   "source": [
    "result = langgraph_applied_rag.invoke(\"how to use conference room?\")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Langgraph Advanced\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== sub_questions =====\n",
      "['How can I request an inventory status report from the Operations Management Team?  ', 'What key details should I include in my request for the inventory status report?']\n",
      "===== sub_questions =====\n",
      "['- What are the steps to book a conference room?', '- What equipment is available in the conference room?', '- What are the rules or guidelines for using the conference room?']\n"
     ]
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from typing import TypedDict, List\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "prompt_split_question = ChatPromptTemplate(\n",
    "    [\n",
    "        \"You are an assistant that helps refine and decompose complex questions.\\n\"\n",
    "        \"Your task is to split the given question into a few concise sub-questions **only if necessary**.\\n\"\n",
    "        \"Do not introduce any new topics or unrelated details.\\n\"\n",
    "        \"Keep the sub-questions **directly relevant to the original question**.\\n\"\n",
    "        \"If the question is already specific, return it as is.\\n\"\n",
    "        \"Ensure that no extra interpretations or additional information beyond the provided question are included.\\n\"\n",
    "        \"\\n\"\n",
    "        \"Original Question: {question}\\n\"\n",
    "        \"Output (one or more refined sub-questions, separated by newlines):\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "class QuestionState(TypedDict):\n",
    "    question: str\n",
    "    sub_questions: List[str]\n",
    "\n",
    "\n",
    "# Node to split question\n",
    "def split_question_node(state: QuestionState) -> QuestionState:\n",
    "    question = state[\"question\"]\n",
    "    response = (\n",
    "        prompt_split_question\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "        | RunnableLambda(lambda result: result.replace(\"\\n\\n\", \"\\n\"))\n",
    "    ).invoke({\"question\": question})\n",
    "\n",
    "    # Convert response to list\n",
    "    sub_questions = response.split(\"\\n\") if \"\\n\" in response else [response]\n",
    "    print(\"===== sub_questions =====\")\n",
    "    print(sub_questions)\n",
    "    return {\n",
    "        \"question\": question,\n",
    "        \"sub_questions\": sub_questions,\n",
    "    }\n",
    "\n",
    "\n",
    "graph = StateGraph(state_schema=QuestionState)\n",
    "\n",
    "graph.add_node(\"split_question\", split_question_node)\n",
    "graph.set_entry_point(\"split_question\")\n",
    "\n",
    "langgraph_question_splitter = graph.compile()\n",
    "\n",
    "# Example executions\n",
    "question = \"I need to check the current inventory levels for an upcoming product launch. How can I request an inventory status report from the Operations Management Team, and what key details should I include in my request?\"\n",
    "result = langgraph_question_splitter.invoke({\"question\": question})\n",
    "\n",
    "question = \"how to use conference room?\"\n",
    "result = langgraph_question_splitter.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_to_dict(l):\n",
    "    return {str(i): v for i, v in enumerate(l)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_dynamic_runnable(runnable):\n",
    "    # Convert dictionary to RunnableParallel Dynamically\n",
    "    @chain\n",
    "    def _dic_to_runnable(d):\n",
    "        return RunnableParallel(\n",
    "            {k: (RunnableLambda(lambda x, key=k: x[key]) | runnable) for k in d.keys()}\n",
    "        ).invoke(d)\n",
    "\n",
    "    return _dic_to_runnable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_summarize_sub_answers = ChatPromptTemplate(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are an assistant summarizing multiple responses for better readability.\\n\"\n",
    "            \"Please consolidate the following sub answers into a clear and concise response.\\n\"\n",
    "            \"Ensure the final answer is not too long while maintaining the key points.\\n\"\n",
    "            \"Sub Answers: {sub_answers}\",\n",
    "        ),\n",
    "        (\"human\", \"My question was {question}. Summarize the key points clearly.\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_answers_chain = (\n",
    "    {\n",
    "        \"question\": RunnablePassthrough(),\n",
    "    }\n",
    "    | langgraph_question_splitter\n",
    "    | RunnableLambda(lambda result: list_to_dict(result[\"sub_questions\"]))\n",
    "    | dict_to_dynamic_runnable(langgraph_applied_rag)\n",
    "    | RunnableLambda(lambda result: list(result.values()))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_bot = (\n",
    "    {\n",
    "        \"question\": RunnablePassthrough(),\n",
    "        \"sub_answers\": sub_answers_chain,\n",
    "    }\n",
    "    | prompt_summarize_sub_answers\n",
    "    | llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== sub_questions =====\n",
      "['How can I request an inventory status report from the Operations Management Team?  ', 'What key details should I include in my request for the inventory status report?']\n",
      "['no', 'yes', 'yes', 'no', 'no']\n",
      "['no', 'no', 'no', 'yes', 'yes']\n",
      "To request an inventory status report for your upcoming product launch, follow these steps:\n",
      "\n",
      "1. **Identify the Contact:** Reach out to Jiwoo Shin (Assistant Manager, jiwoo.shin@xyzshop.com), with Hyeonseo Kim (Junior Staff, hyeonseo.kim@xyzshop.com) as a backup.\n",
      "\n",
      "2. **Compose Your Email:** Include the following key details:\n",
      "   - Your name and position.\n",
      "   - Purpose of the request (e.g., checking inventory levels for a product launch).\n",
      "   - Specific timeframe for the inventory needed (e.g., current levels).\n",
      "   - Preferred data format (e.g., Excel, PDF).\n",
      "   - Key metrics to include (e.g., total inventory levels, discrepancies).\n",
      "   - Deadline for the report (e.g., \"Please send by Friday 5:00 PM\").\n",
      "   - Your contact information for follow-up.\n",
      "\n",
      "3. **Provide Context:** If relevant, mention any specific projects or issues related to your request.\n",
      "\n",
      "4. **Follow Up:** If you don't receive a response within a few days, send a polite follow-up email.\n",
      "\n",
      "Here’s a sample email template:\n",
      "\n",
      "---\n",
      "Subject: Request for Inventory Status Report\n",
      "\n",
      "Dear Jiwoo,\n",
      "\n",
      "I hope this message finds you well. I am writing to request an inventory status report for our upcoming product launch. Specifically, I need the current inventory levels.\n",
      "\n",
      "If possible, I would appreciate receiving this report in [preferred format] by [insert deadline]. \n",
      "\n",
      "Thank you for your assistance!\n",
      "\n",
      "Best regards,  \n",
      "[Your Name]  \n",
      "[Your Position]  \n",
      "[Your Contact Information]  \n",
      "---\n",
      "\n",
      "Sending your email during business hours can help ensure a timely response.\n"
     ]
    }
   ],
   "source": [
    "response = chat_bot.invoke(\n",
    "    \"I need to check the current inventory levels for an upcoming product launch.\\n\"\n",
    "    \"How can I request an inventory status report from the Operations Management Team,\\n\"\n",
    "    \"and what key details should I include in my request?\"\n",
    ")\n",
    "print(response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-opentutorial-1IH4x998-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
