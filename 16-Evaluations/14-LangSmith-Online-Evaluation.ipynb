{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangSmith Online Evaluation\n",
    "\n",
    "- Author: [JeongGi Park](https://github.com/jeongkpa)\n",
    "- Design: []()\n",
    "- Peer Review: \n",
    "- This is a part of [LangChain Open Tutorial](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial)\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/LangChain-OpenTutorial/LangChain-OpenTutorial/blob/main/01-Basic/07-LCEL-Interface.ipynb) [![Open in GitHub](https://img.shields.io/badge/Open%20in%20GitHub-181717?style=flat-square&logo=github&logoColor=white)](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial/blob/main/01-Basic/07-LCEL-Interface.ipynb)\n",
    "\n",
    "## Overview\n",
    "This module provides tools to evaluate and track the performance of language models using LangSmith's online evaluation capabilities.\n",
    "\n",
    "\n",
    "By setting up chains and using custom configurations, users can assess model outputs, including hallucination detection and context recall, ensuring robust performance in various scenarios.\n",
    "\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "- [Overview](#overview)\n",
    "- [Environment Setup](#environment-setup)\n",
    "- [LCEL Interface](#LCEL-Interface)\n",
    "\n",
    "### References\n",
    "\n",
    "- [Langsmith DOC](https://docs.smith.langchain.com/)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "Set up the environment. You may refer to [Environment Setup](https://wikidocs.net/257836) for more details.\n",
    "\n",
    "**[Note]**\n",
    "- `langchain-opentutorial` is a package that provides a set of easy-to-use environment setup, useful functions and utilities for tutorials. \n",
    "- You can checkout the [`langchain-opentutorial`](https://github.com/LangChain-OpenTutorial/langchain-opentutorial-pypi) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install langchain-opentutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "from langchain_opentutorial import package\n",
    "\n",
    "package.install(\n",
    "    [\n",
    "        \"langsmith\",\n",
    "        \"langchain-openai\",\n",
    "        \"langchain_community\"\n",
    "    ],\n",
    "    verbose=False,\n",
    "    upgrade=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variables have been set successfully.\n"
     ]
    }
   ],
   "source": [
    "# Set environment variables\n",
    "from langchain_opentutorial import set_env\n",
    "\n",
    "set_env(\n",
    "    {\n",
    "        \"OPENAI_API_KEY\": \"\",\n",
    "        \"LANGCHAIN_API_KEY\": \"\",\n",
    "        \"LANGCHAIN_TRACING_V2\": \"true\",\n",
    "        \"LANGCHAIN_ENDPOINT\": \"https://api.smith.langchain.com\",\n",
    "        \"LANGCHAIN_PROJECT\": \"LangSmith-Online-Evaluation\",\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Note] If you are using a `.env` file, proceed as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up Chain for online evaluations\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "\n",
    "class PDFRAG:\n",
    "    def __init__(self, file_path: str, llm):\n",
    "        self.file_path = file_path\n",
    "        self.llm = llm\n",
    "\n",
    "    def load_documents(self):\n",
    "        # Load Documents\n",
    "        loader = PyMuPDFLoader(self.file_path)\n",
    "        docs = loader.load()\n",
    "        return docs\n",
    "\n",
    "    def split_documents(self, docs):\n",
    "        # Split Documents\n",
    "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=50)\n",
    "        split_documents = text_splitter.split_documents(docs)\n",
    "        return split_documents\n",
    "\n",
    "    def create_vectorstore(self, split_documents):\n",
    "        # Embedding\n",
    "        embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "        # Create DB\n",
    "        vectorstore = FAISS.from_documents(\n",
    "            documents=split_documents, embedding=embeddings\n",
    "        )\n",
    "        return vectorstore\n",
    "\n",
    "    def create_retriever(self):\n",
    "        vectorstore = self.create_vectorstore(\n",
    "            self.split_documents(self.load_documents())\n",
    "        )\n",
    "        # Retriever\n",
    "        retriever = vectorstore.as_retriever()\n",
    "        return retriever\n",
    "\n",
    "    def create_chain(self, retriever):\n",
    "        # Create Prompt\n",
    "        prompt = PromptTemplate.from_template(\n",
    "            \"\"\"You are an assistant for question-answering tasks. \n",
    "        Use the following pieces of retrieved context to answer the question. \n",
    "        If you don't know the answer, just say that you don't know. \n",
    "\n",
    "        #Context: \n",
    "        {context}\n",
    "\n",
    "        #Question:\n",
    "        {question}\n",
    "\n",
    "        #Answer:\"\"\"\n",
    "        )\n",
    "\n",
    "        # Chain\n",
    "        chain = (\n",
    "            {\n",
    "                \"context\": retriever,\n",
    "                \"question\": RunnablePassthrough(),\n",
    "            }\n",
    "            | prompt\n",
    "            | self.llm\n",
    "            | StrOutputParser()\n",
    "        )\n",
    "        return chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jgpar\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\langchain-opentutorial-cyV7o7ra-py3.11\\Lib\\site-packages\\langchain_community\\document_loaders\\parsers\\pdf.py:322: UserWarning: Warning: Empty content on page 5 of document data/Introduction_LangChain.pdf\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Create a PDFRAG object\n",
    "rag = PDFRAG(\n",
    "    \"data/Introduction_LangChain.pdf\",\n",
    "    ChatOpenAI(model=\"gpt-4o-mini\", temperature=0),\n",
    ")\n",
    "\n",
    "# Create a retriever\n",
    "retriever = rag.create_retriever()\n",
    "\n",
    "# Create a chain\n",
    "rag_chain = rag.create_chain(retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel, RunnablePassthrough\n",
    "\n",
    "# Create a RunnableParallel object.\n",
    "evaluation_runnable = RunnableParallel(\n",
    "    {\n",
    "        \"context\": retriever,\n",
    "        \"answer\": rag_chain,\n",
    "        \"question\": RunnablePassthrough(),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = evaluation_runnable.invoke(\"What are the main components of LangChain's architecture?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableConfig\n",
    "\n",
    "# 태그를 설정합니다.\n",
    "hallucination_config = RunnableConfig(tags=[\"hallucination_eval\"])\n",
    "context_recall_config = RunnableConfig(tags=[\"context_recall_eval\"])\n",
    "all_eval_config = RunnableConfig(tags=[\"hallucination_eval\", \"context_recall_eval\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 체인 실행\n",
    "_ = evaluation_runnable.invoke(\"What are the main components of LangChain's architecture?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hallucination 평가 요청\n",
    "_ = evaluation_runnable.invoke(\n",
    "    \"What are the main components of LangChain's architecture?\", config=hallucination_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Context Recall 평가 요청\n",
    "_ = evaluation_runnable.invoke(\n",
    "    \"What are the main components of LangChain's architecture?\",\n",
    "    config=context_recall_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 평가 요청\n",
    "_ = evaluation_runnable.invoke(\n",
    "    \"What are the main components of LangChain's architecture?\", config=all_eval_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-opentutorial-cyV7o7ra-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
