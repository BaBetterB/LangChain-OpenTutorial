{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Asking Humans for Help: Customizing State in LangGraph\n",
    "\n",
    "- Author: [Hwayoung Cha](https://github.com/forwardyoung)\n",
    "- Design: []()\n",
    "- Peer Review: []()\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain-academy/blob/main/module-4/sub-graph.ipynb) [![Open in LangChain Academy](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66e9eba12c7b7688aa3dbb5e_LCA-badge-green.svg)](https://academy.langchain.com/courses/take/intro-to-langgraph/lessons/58239937-lesson-2-sub-graphs)\n",
    "\n",
    "## Overview\n",
    "\n",
    "This tutorial demonstrates how to extend a chatbot using LangGraph by adding a \"human\" node, allowing the system to optionally ask humans for help. It introduces state customization with an \"ask_human\" flag and shows how to handle interruptions and manual state updates. The tutorial also covers graph visualization, conditional logic, and integrating tools like web search and human assistance.\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "- [Overview](#overview)\n",
    "- [Environement Setup](#environment-setup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- [Tavily Search](https://python.langchain.com/docs/integrations/tools/tavily_search/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "Set up the environment. You may refer to [Environment Setup](https://wikidocs.net/257836) for more details.\n",
    "\n",
    "**[Note]**\n",
    "- `langchain-opentutorial` is a package that provides a set of easy-to-use environment setup, useful functions and utilities for tutorials. \n",
    "- You can checkout the [`langchain-opentutorial`](https://github.com/LangChain-OpenTutorial/langchain-opentutorial-pypi) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install langchain-opentutorial matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "from langchain_opentutorial import package\n",
    "\n",
    "package.install(\n",
    "    [\n",
    "        \"langsmith\",\n",
    "        \"langgraph\",\n",
    "        \"langchain_core\",\n",
    "        \"langchain_openai\",\n",
    "        \"langchain_community\",\n",
    "        \"matplotlib\"\n",
    "    ],\n",
    "    verbose=False,\n",
    "    upgrade=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variables have been set successfully.\n"
     ]
    }
   ],
   "source": [
    "# Set environment variables\n",
    "from langchain_opentutorial import set_env\n",
    "\n",
    "set_env(\n",
    "    {\n",
    "        \"OPENAI_API_KEY\": \"\",\n",
    "        \"LANGSMITH_TRACING_V2\": \"true\",\n",
    "        \"LANGSMITH_ENDPOINT\": \"https://api.smith.langchain.com\",\n",
    "        \"LANGCHAIN_API_KEY\": \"\",\n",
    "        \"LANGCHAIN_PROJECT\": \"\", # set the project name same as the title\n",
    "        \"TAVILY_API_KEY\": \"\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can alternatively set OPENAI_API_KEY in .env file and load it.\n",
    "\n",
    "[Note] This is not necessary if you've already set OPENAI_API_KEY in previous steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configuration file to manage API keys as environment variables\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load API key information\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up the Node to Ask Humans for Help\n",
    "\n",
    "Extends the `State` class to include an `ask_human` flag and defines the `HumanRequest` tool schema using `TypedDict` and `BaseModel`. This allows the chatbot to formally request human assistance when needed, adding flexibility to its decision-making process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_community.tools import TavilySearchResults\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, START\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time, we will add a state (`ask_human`) to determine whether the chatbot should ask a human for help during the conversation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    # List for messages\n",
    "    messages: Annotated[list, add_messages]\n",
    "    # State to determine whether to ask a human for help\n",
    "    ask_human: bool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the schema for the `human` request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "class HumanRequest(BaseModel):\n",
    "    \"\"\"Forward the conversation to an expert. Use when you can't assist directly or the user needs assistance that exceeds your authority.\n",
    "    To use this function, pass the user's 'request' so that an expert can provide appropriate guidance.\n",
    "    \"\"\"\n",
    "\n",
    "    request: str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define the chatbot node. \n",
    "The key modification here is that the chatbot will toggle the `ask_human` flag if it calls the `RequestAssistance` flag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Add tools\n",
    "tool = TavilySearchResults(max_results=3)\n",
    "\n",
    "# Add the list of tools (including the HumanRequest tool)\n",
    "tools = [tool, HumanRequest]\n",
    "\n",
    "# Add the LLM\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# Bind tools to the LLM\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "def chatbot(state: State):\n",
    "    # Generate a response using the LLM tool calls\n",
    "    response = llm_with_tools.invoke(state[\"messages\"])\n",
    "\n",
    "    # Initialize the ask_human flag\n",
    "    ask_human = False\n",
    "\n",
    "    # If there is a tool call and its name is 'HumanRequest'\n",
    "    if response.tool_calls and response.tool_calls[0][\"name\"] == HumanRequest.__name__:\n",
    "        ask_human = True\n",
    "\n",
    "    # Return the messages and the ask_human state\n",
    "    return {\"messages\": [response], \"ask_human\": ask_human}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create the graph builder and add the `chatbot` and `tools` nodes to the graph, as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x22d32598290>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the state graph\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "# Add the chatbot node\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "# Add the tools node\n",
    "graph_builder.add_node(\"tools\", ToolNode(tools=[tool]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up the Human Node\n",
    "\n",
    "Next, we create the `human` node. \n",
    "\n",
    "This node primarily serves as a placeholder to trigger an interrupt in the graph. If the user does not manually update the state during the `interrupt`, the LLM will insert a tool message to indicate that the human was asked for help but did not respond.\n",
    "\n",
    "This node also resets the `ask_human` flag to ensure the graph does not revisit the node unless another request is made."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Reference Image\n",
    "\n",
    "![](./assets/08-langgraph-state-customization.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x22d32598290>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage, ToolMessage\n",
    "\n",
    "# Function to create a response message (for generating ToolMessage)\n",
    "def create_response(response: str, ai_message: AIMessage):\n",
    "    return ToolMessage(\n",
    "        content=response,\n",
    "        tool_call_id=ai_message.tool_calls[0][\"id\"],\n",
    "    )\n",
    "\n",
    "# Human node processing\n",
    "def human_node(state: State):\n",
    "    new_messages = []\n",
    "    if not isinstance(state[\"messages\"][-1], ToolMessage):\n",
    "        # If there is no response from the human\n",
    "        new_messages.append(\n",
    "            create_response(\"No response from human.\", state[\"messages\"][-1])\n",
    "        )\n",
    "    return {\n",
    "        # Add new messages\n",
    "        \"messages\": new_messages,\n",
    "        # Reset the flag\n",
    "        \"ask_human\": False,\n",
    "    }\n",
    "\n",
    "# Add the human node to the graph\n",
    "graph_builder.add_node(\"human\", human_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define the conditional logic.\n",
    "\n",
    "The `select_next_node` function routes the path to the `human` node if the flag is set. Otherwise, it uses the prebuilt `tools_condition` function to select the next node.\n",
    "\n",
    "The `tools_condition` function simply checks if the `chatbot` used `tool_calls` in the response message.\n",
    "\n",
    "If so, it routes to the `action` node. Otherwise, it ends the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x22d32598290>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import END\n",
    "\n",
    "# Function to select the next node\n",
    "def select_next_node(state: State):\n",
    "    # Check if the chatbot should ask a human\n",
    "    if state[\"ask_human\"]:\n",
    "        return \"human\"\n",
    "    # Otherwise, follow the same path as before\n",
    "    return tools_condition(state)\n",
    "\n",
    "# Add conditional edges\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    select_next_node,\n",
    "    {\"human\": \"human\", \"tools\": \"tools\", END: END},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we connect the edges and compile the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add edge: from 'tools' to 'chatbot'\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "\n",
    "# Add edge: from 'human' to 'chatbot'\n",
    "graph_builder.add_edge(\"human\", \"chatbot\")\n",
    "\n",
    "# Add edge: from START to 'chatbot'\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "\n",
    "# Initialize memory storage\n",
    "memory = MemorySaver()\n",
    "\n",
    "# Compile the graph: use memory checkpointing\n",
    "graph = graph_builder.compile(\n",
    "    checkpointer=memory,\n",
    "    # Set interrupt before 'human'\n",
    "    interrupt_before=[\"human\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'StateGraph' object has no attribute 'conditional_edges'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 60\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# 조건부 엣지 정보 추출\u001b[39;00m\n\u001b[0;32m     59\u001b[0m conditional_edges \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 60\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m node, condition \u001b[38;5;129;01min\u001b[39;00m \u001b[43mgraph_builder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconditional_edges\u001b[49m\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m target \u001b[38;5;129;01min\u001b[39;00m condition[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124medges\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[0;32m     62\u001b[0m         conditional_edges\u001b[38;5;241m.\u001b[39mappend((node, target))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'StateGraph' object has no attribute 'conditional_edges'"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from langgraph.graph import StateGraph\n",
    "\n",
    "def visualize_graph(nodes, edges, conditional_edges=None):\n",
    "    \"\"\"\n",
    "    그래프를 시각화하는 함수.\n",
    "    노드와 엣지를 시각적으로 표현합니다.\n",
    "    \"\"\"\n",
    "    # 방향성 그래프 생성\n",
    "    G = nx.DiGraph()\n",
    "\n",
    "    # 노드 추가\n",
    "    for node in nodes:\n",
    "        G.add_node(node)\n",
    "\n",
    "    # 일반 엣지 추가\n",
    "    for edge in edges:\n",
    "        G.add_edge(edge[0], edge[1])\n",
    "\n",
    "    # 조건부 엣지 추가 (점선으로 표시)\n",
    "    if conditional_edges:\n",
    "        for edge in conditional_edges:\n",
    "            G.add_edge(edge[0], edge[1], style=\"dashed\")\n",
    "\n",
    "    # 그래프 레이아웃 설정\n",
    "    pos = nx.spring_layout(G)  # 노드 위치를 자동으로 배치\n",
    "\n",
    "    # 노드와 엣지 그리기\n",
    "    nx.draw_networkx_nodes(G, pos, node_size=2000, node_color='lightblue')  # 노드 그리기\n",
    "    nx.draw_networkx_edges(G, pos, arrowstyle='->', arrowsize=20, edge_color='gray')  # 일반 엣지 그리기\n",
    "\n",
    "    # 조건부 엣지 그리기 (점선)\n",
    "    if conditional_edges:\n",
    "        dashed_edges = [(u, v) for u, v, d in G.edges(data=True) if d.get(\"style\") == \"dashed\"]\n",
    "        nx.draw_networkx_edges(G, pos, edgelist=dashed_edges, arrowstyle='->', arrowsize=20, edge_color='gray', style=\"dashed\")\n",
    "\n",
    "    # 노드 레이블 그리기\n",
    "    nx.draw_networkx_labels(G, pos, font_size=12, font_weight='bold')\n",
    "\n",
    "    # 그래프 표시\n",
    "    plt.title(\"Graph Visualization\")\n",
    "    plt.axis('off')  # 축 숨기기\n",
    "    plt.show()\n",
    "\n",
    "# 그래프 빌더 생성\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "# 노드 추가\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "graph_builder.add_node(\"human\", human_node)\n",
    "\n",
    "# 엣지 추가\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "graph_builder.add_edge(\"chatbot\", END)\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    lambda state: \"human\" if state[\"ask_human\"] else END,\n",
    "    {\"human\": \"human\", END: END}\n",
    ")\n",
    "graph_builder.add_edge(\"human\", \"chatbot\")\n",
    "\n",
    "# 그래프 컴파일\n",
    "graph = graph_builder.compile()\n",
    "\n",
    "# 그래프 빌더에서 노드와 일반 엣지 정보 추출\n",
    "nodes = list(graph_builder.nodes.keys())  # 노드 목록\n",
    "edges = list(graph_builder.edges)  # 일반 엣지 목록\n",
    "\n",
    "# 조건부 엣지 정보 추출\n",
    "conditional_edges = []\n",
    "if hasattr(graph_builder, \"_conditional_edges\"):\n",
    "    for node, condition in graph_builder._conditional_edges.items():\n",
    "        for target in condition[\"edges\"].values():\n",
    "            conditional_edges.append((node, target))\n",
    "\n",
    "# 그래프 시각화\n",
    "visualize_graph(nodes, edges, conditional_edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `chatbot` node behaves as follows:\n",
    "\n",
    "- The chatbot can ask a human for help (chatbot->select->human)\n",
    "- It can call a search engine tool (chatbot->select->action)\n",
    "- Or it can respond directly (chatbot->select->`end`).\n",
    "\n",
    "Once an action or request is made, the graph switches back to the `chatbot` node to continue the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_input = \"I need expert help to build this AI agent. Please search for an answer.\" (Case where it performs a web search instead of asking a human)\n",
    "user_input = \"I need expert help to build this AI agent. Can you request assistance?\"\n",
    "\n",
    "# Config setup\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Stream or call the second positional argument as configuration\n",
    "events = graph.stream(\n",
    "    {\"messages\": [(\"user\", user_input)]}, config, stream_mode=\"values\"\n",
    ")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        # Pretty print the last message\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notice:** The `LLM` has called the provided \"`HumanRequest`\" tool, and an interrupt has been set. Let's check the graph state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a snapshot of the graph state\n",
    "snapshot = graph.get_state(config)\n",
    "\n",
    "# Access the next snapshot state\n",
    "snapshot.next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The graph state is actually **interrupted** before the `'human'` node. In this scenario, you can act as the \"expert\" and manually update the state by adding a new `ToolMessage` with your input.\n",
    "\n",
    "To respond to the chatbot's request, follow these steps:\n",
    "\n",
    "1. Create a `ToolMessage` containing your response. This will be passed back to the `chatbot`.\n",
    "2. Call `update_state` to manually update the graph state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the AI message\n",
    "ai_message = snapshot.values[\"messages\"][-1]\n",
    "\n",
    "# Create a human response\n",
    "human_response = (\n",
    "    \"Experts are here to help! We highly recommend checking out LangGraph for building your agent. \"\n",
    "    \"It is much more stable and scalable than a simple autonomous agent. \"\n",
    "    \"You can find more information at https://wikidocs.net/233785.\"\n",
    ")\n",
    "\n",
    "# Create a tool message\n",
    "tool_message = create_response(human_response, ai_message)\n",
    "\n",
    "# Update the graph state\n",
    "graph.update_state(config, {\"messages\": [tool_message]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check the state to confirm that the response has been added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the message values from the graph state\n",
    "graph.get_state(config).values[\"messages\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we **resume** the graph by passing `None` as the input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate an event stream from the graph\n",
    "events = graph.stream(None, config, stream_mode=\"values\")\n",
    "\n",
    "# Process each event\n",
    "for event in events:\n",
    "    # Print the last message if messages are present\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's check the final result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the final state\n",
    "state = graph.get_state(config)\n",
    "\n",
    "# Print the messages step by step\n",
    "for message in state.values[\"messages\"]:\n",
    "    message.pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-opentutorial-GHgbjDj7-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
